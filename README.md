# rag-docq-ollama
A performant Retrieval-Augmented Generation (RAG) pipeline using Ollama to run local LLMs like gpt-oss:20b, llama3:8b, qwen3:4b, and gemma3:4b. Supports PDFs, JPGs, PNGs via OCR, uses Sentence-Transformers for embeddings and ChromaDB for vector storage. Includes benchmarking tools for speed, memory, and answer quality across models.
