# RAG GPU Quantized LLM Benchmark

A GPU-accelerated Retrieval-Augmented Generation (RAG) benchmarking framework using quantized large language models (LLMs) for fast and accurate document question answering.

## Features

- Supports multi-format input: PDF, JPG, JPEG, PNG  
- OCR text extraction with Tesseract  
- Document embedding using SentenceTransformers  
- Vector storage and similarity search with ChromaDB  
- Inference on local quantized LLMs via Ollama-compatible API  
- Performance benchmarking: speed, memory, accuracy  
- Modular and extensible for testing various models
